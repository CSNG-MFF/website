<!DOCTYPE html>
<html lang="en-us">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <!--[if lt IE 9]>
    <meta http-equiv="refresh" content="0;url=http://jnrbsn.github.io/browser-upgrade/">
    <style>body{display:none;}</style>
    <![endif]-->
    <title>CSNG / Projects</title>
    <meta name="title" content="CSNG">
    <meta name="description" content="CSNG: ">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="keywords"
        content="Jan Antolik,jan,antolik,Antolik,Computational,Neuroscience,Vision,Models,System Identification,Science,Projects,Cortex,CSNG,Prague Neuroscience,Charles University,V1,V1 model,Neuroprosthesis, artificial vision, csng">
    <link rel="icon" type="image/png" href="./assets/img/favicon.png">
    <link rel="stylesheet" href="./assets/css/main.css">
    <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Open+Sans:400,600,700,400italic,600italic,700italic">
    <link rel="stylesheet" href="./vendor/academicons/academicons.css">
    <link rel="stylesheet" href="./vendor/fontello/css/fontello.css">
    <link rel="stylesheet" href="./vendor/fontello/css/animation.css">
    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link href="https://fonts.googleapis.com/css2?family=Lato:wght@300&family=Major+Mono+Display&family=Press+Start+2P&family=Roboto:wght@100&family=Ubuntu:wght@300&family=Varela+Round&display=swap" rel="stylesheet">      

<body>
    <div class="container">
        <div style="background-color:#fff">
            <div class="navigation">
                <div class="cuni-logo">
                </div>
                <div class="csng-text">
                    Computational Systems Neuroscience Group
                </div>
                <ul style="vertical-align: bottom; margin-top: -12px">
                    <li><a href="./"><i class="icon-info-circled"></i><span>About</span></a></li>
                    <li><a href="./research.html"><i class="icon-wrench"></i><span>Research</span></a></li>
                    <li><a href="./software.html"><i class="icon-wrench"></i><span>Software</span></a></li>
                    <li><a href="./publications.html"><i class="icon-wrench"></i><span>Publications</span></a></li>
                    <li><a href="./people.html"><i class="icon-wrench"></i><span>People</span></a></li>
                    <li><a href="./students.html"><i class="icon-wrench"></i><span>For students</span></a></li>
                    <li><a href="./funding.html"><i class="icon-wrench"></i><span>Fundings</span></a></li>
                    <li><a href="./join_us.html"><i class="icon-wrench"></i><span>Join us!</span></a></li>
                </ul>
            </div>
        </div>
        <div class="content">
            <table style="border-spacing: 30px 0px">

   <tr class="titlerow">
      <td></td>
      <td><strong>Facets of illusory contour sensitivity in early visual system. </strong></td>
   </tr>
   <tr>
      <td class="projectrow" valign="center"><img src="./assets/img/illusory_contours.png" width=180></img></td>
      <td class="projectrow" valign="center">
         <p>
            Sensitivity to illusory contours is a key signature of higher-level visual processing, and increasing number
            of neurons sensitive to illusory contours along the ventral visual pathway has been identified in
            experiments. In this project we will utilize our detailed models of cat V1 (and later V2) to study how such
            sensitivity to illusory contours emerges along the visual hierarchy, and how is it implemented in the neural
            substrate.  
         </p>
      </td>
   </tr>

   <tr class="titlerow">
      <td></td>
      <td><strong>Model of V2 processing and beyond.</strong></td>
   </tr>
   <tr>
      <td class="projectrow" valign="center"><img src="./assets/img/v1_v2.svg" width=180></img></td>
      <td class="projectrow" valign="center">
         <p>
            Having successfully created a comprehensive model of V1 (see below), we are now expanding our modelling
            efforts beyond the primary visual cortical area, focusing particularly on area V2 and in future also V4.
            Upon construction of the expanded model we will focus on probing the model for presence of sensitivity
            to higher-order correlations in the visual stimuli, sensitivity to illusory contours and presence of
            figure-ground segregation signals.   
         </p>
      </td>
   </tr>

   <tr class="titlerow">
      <td></td>
      <td><strong>Cortical visual prosthesis: a detailed large-scale cortical simulation study.</strong></td>
   </tr>
   <tr>
      <td class="projectrow" valign="center"><img src="./assets/img/light_response.png" width=180></img></td>
      <td class="projectrow" valign="center">
         <p>
            Recent advances in optogenetics are opening path towards development of light stimulation based cortical
            prosthetic devices. However, two fundamental aspects of the cortical optogenetic prosthesis remain unclear.
            First, the exact behavior of cortical physiology under direct stimulation, especially in the context of
            active and functionally specific neural circuitry, is poorly understood. Second, we lack strategies for
            transformation of visual stimuli into light patterns that induce cortical activity similar to that due to
            stimulation via retina. We address these issues using a large-scale spiking neural network modeling strategy
            of high biological fidelity. We examine the relationship between configuration of light delivered to cortex
            and the resulting spatio-temporal pattern of activity evoked in the simulated cortex. We design a protocol
            for translation of visual stimuli to activation patterns of LED array and provide a assessment of the
            resulting cortical activations with respect to the natural vision condition.
         </p>
      </td>
   </tr>

   <tr class="titlerow">
      <td></td>
      <td><strong>A reassessment of stimulus dependence of receptive fields in primary visual cortex.</strong></td>
   </tr>
   <tr>
      <td class="projectrow" valign="center"><img src="./assets/img/margot.png" width=180></img></td>
      <td class="projectrow" valign="center">
         <p>
            This is the PhD project of <a href="https://www.unic.cnrs-gif.fr/people/Margot_Larroche/">Margot
               Larroche</a> that I supervise together with <a
               href="https://www.unic.cnrs-gif.fr/people/Cyril_Monier/">Cyril Monier</a>.
            Estimation of RF model based on an ensemble of visual stimuli and associated neural responses is a common
            approach for studying neuronal coding in V1. The interpretability of such models has, however, been
            regularly challenged due to the stimulus dependence of their fits, i.e. their failure to generalize between
            different stimulus statistics. However, the compared stimulus sets were often insufficiently controlled for
            a number of basic parameters, putting in question their interpretation. In this project, we use a carefully
            designed set of visual stimuli to characterize short-term RF stimulus-dependence phenomena using dense
            multi-electrode extracellular recordings of neuronal responses in cat V1. We estimate RF models including
            novel multi-stage L-NL cascade architecture for each stimulus type, compute cross-prediction performances,
            and analyze differences between fits.
         </p>
      </td>
   </tr>

   <tr class="titlerow">
      <td></td>
      <td><strong>Model of thalamo-cortical loop of cat visual system.</strong></td>
   </tr>
   <tr>
      <td class="projectrow" valign="center"><img src="./assets/img/thalmocortical_loop_project_logo.png"
            width=180></img></td>
      <td class="projectrow" valign="center">
         <p>
            This is the PhD project of <a href="https://www.researchgate.net/profile/Domenico_Guarino">Domenico
               Guarino</a>.
            What are the functional properties of the thalamo-cortical loop? In the early visual system of the cat, the
            feedforward pathway going from
            the lateral geniculate nucleus (LGN) to the primary visual cortex (V1) is well characterized both
            anatomically and functionally. But, in
            spite of the amount of experimental work, there is still poor agreement on possible roles for the feedback
            pathway going from V1 to
            LGN. We addressed this issue dividing the available experimental data into open-loop conditions, where the
            thalamus was probed in isolation
            from cortex, and closed-loop conditions, where the intact system was probed. We explored these same
            conditions with a biologically
            plausible integrative large-scale model of the cat early visual system that includes: LGN, peri-geniculate
            nucleus (PGN), and V1.
         </p>
      </td>
   </tr>


   <tr class="titlerow">
      <td></td>
      <td><strong>Comprehensive model of cat primary visual cortex.</strong></td>
   </tr>
   <tr>
      <td class="projectrow" valign="center"><img src="./assets/img/LSV1M_logo.png" width=180></img></td>
      <td class="projectrow" valign="center">
         <p>
            Neuroscience has produced an immense amount of data on the function and anatomy of early visual areas.
            However, the transformation of this knowledge
            into a general coherent understanding has so far been limited. Computational modeling can integrate such
            fragmented data by building models of brain
            structures that satisfy the broad range of constraints imposed by experiments, thus advancing our
            understanding of their computational role,
            and their implementation in the neural substrate. In this project we aim to build a comprehensive
            multi-scale spiking model of cat primary visual
            cortex which satisfies a unprecedented range of experimentally identified anatomical, statistical and
            functional properties. In future we will
            expand the scope of the model beyond primary visual cortex.
         </p>
      </td>
   </tr>



   <tr class="titlerow">
      <td></td>
      <td><strong>Receptive fields identification in local populations of V1 neurons.</strong></td>
   </tr>
   <tr>
      <td class="projectrow" valign="center"><a href="https://github.com/antolikjan/lscsm"><img
               src="./assets/img/LSCSM_logo.png" width=180></img></a></td>
      <td class="projectrow" valign="center">
         <p>
            One of the key goals of sensory neuroscience is to identify the relationship between stimuli and neural
            responses.
            A common approch of identifying the stimulus-response function is to present a large collection
            of stimuli while responses of sensory neurons are recorded. Numerous methods for estimating the
            stimulus-response function from such data has been
            proposed in the past but no took advantage of the known architecture of primary visual cortex (V1) and the
            fact that a local population of
            V1 neurons shares limited pool of thalamic inputs. In this project we investigate a novel method for
            estimating the stimulus-response function
            in a population of neurons that implicitly assumes the discussed architecture of V1.
         </p>
      </td>
   </tr>

</table>
        </div>
        <div style="background-color:#fff; border-radius: 0 0 25px 25px;">
            <footer style="font-size: 13px;">
                <p><i class="icon-cc"></i>&nbsp;2020&ndash;2021&nbsp;&nbsp;Computational Systems
                    Neuroscience Group</br>
                    This site is powered by <a href="http://jekyllrb.com/">Jekyll</a> and hosted on
                    <a href="https://pages.github.com/">GitHub Pages</a>. Based on personal website of <a href="http://jnrbsn.com/">Jonathan Robson</a> (<a href="http://creativecommons.org/licenses/by-nc-sa/4.0/" >CC BY-NC-SA 4.0</a>).
                </p>
            </footer>
        </div>
    </div>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
    <script src="./vendor/autolinker/Autolinker.min.js?rev="></script>
    <script src="./assets/js/main.js?rev="></script>
</body>

</html>